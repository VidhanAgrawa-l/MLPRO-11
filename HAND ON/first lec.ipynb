{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AGENDA\n",
    "\n",
    "1- Set up the github {Repository} \n",
    "a)new environment \n",
    "b)setup. py\n",
    "c)requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "END TO END ML PROJECT \n",
    "\n",
    "LECTURE -1 \n",
    "\n",
    "s1- ek aalag folder bna lo cell-y mai and open it in vscode via .code in terminal\n",
    "s2- create virtual env\n",
    "\n",
    "    Check the Python version:python3 --version\n",
    "    Navigate to the folder where you want to create the virtual environment:cd /path/to/your/project\n",
    "    Create the virtual environment:python3 -m venv venv(venv is the name of the virtual environment directory.)\n",
    "    Activate the environment to use it:source venv/bin/activate\n",
    "    Deactivate the Virtual Environment:deactivate\n",
    "    simply delete the venv directory:rm -rf venv\n",
    "\n",
    "s3- use this git command in terminal for\n",
    "\n",
    "git init(initialze empty git repo)\n",
    "git add README. md (make it directly in vs code file)\n",
    "git commit -m \"first commit\"\n",
    "git branch -M main\n",
    "git remote add origin https://github.com/krishnaik06/mlproject.git (to meke git and vscode in sink)\n",
    "git push -u origin main(you have to do it every time when u want to push it into the repo)\n",
    "\n",
    "Git Configuration(if u are doing it first time )\n",
    "git config --global user.name \"John Doe\" (-git config --global user.name) sirf itni comand se check kr skte hai \n",
    "git config --global user.email johndoe@example.com\n",
    "\n",
    "s4- use git hub and create .gitignore file and **dont forgot to choose python **\n",
    "\n",
    "s5- make \n",
    "    requiremnet.txt (all the package that are needed in project are mention here and can be install from here )\n",
    "    setup.py(buildind your applicaation as package itself so, u can also daalska in python pypi)\n",
    "\n",
    "    ->The Python Package Index (PyPI) is a repository of software for the Python programming language.\n",
    "    ->Find, install and publish Python packages with the Python Package Index\n",
    "\n",
    "s6- make a folder name src(source) \n",
    "    make __init__.py inside it so that \n",
    "    The __init__.py file plays a key role in Python package management. Its primary function is to indicate to Python that a directory should be treated as a package.\n",
    "\n",
    "s7- use the git command to make the required changes\n",
    "    git add .\n",
    "    git status\n",
    "    git commit -m \"setup\"\n",
    "    git push -u origin main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LECTURE -2\n",
    "\n",
    "s1- \n",
    "src\n",
    "    _init_.py   ->(sab mai bnao)\n",
    "    exception.py ()\n",
    "    logger.py (wrote about it in logger.py )\n",
    "    utils.py(utils.py is an essential part of clean and reusable code design in a project, serving as a hub for shared functionality.)\n",
    "\n",
    "    components (all the module that we are going to create)\n",
    "        _init_.py  ->(sab mai bnao)\n",
    "        data_ingestion.py \n",
    "        data_transformation.py \n",
    "        model_trainer.py\n",
    "\n",
    "    pipeline \n",
    "        _init_.py   ->(sab mai bnao)\n",
    "        predict_pipeline.py \n",
    "        train_pipeline.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "LECTURE -3\n",
    "\n",
    "s1- notebook (folder)\n",
    "        data(ke andr csv file)\n",
    "        1.EDA\n",
    "        2.model trianing\n",
    "\n",
    "s2- EDA and model trainnng ke code toh read kr lo ek baar \n",
    "\n",
    "abhi tak aapan notebook mai code kra hai pr aab aapana\n",
    "modular(make function and specific code in specific folder) coding krnega "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LECTURE -4\n",
    "\n",
    "Let me break down each step of this code by explaining the \"why\" behind every decision. This will help us understand the reasoning and purpose behind each component.\n",
    "\n",
    "**1. Why use a @dataclass for configuration?**\n",
    "```python\n",
    "@dataclass\n",
    "class DataIngestionConfig:\n",
    "    train_data_path: str = os.path.join('artifacts', \"train.csv\")\n",
    "    test_data_path: str = os.path.join('artifacts', \"test.csv\")\n",
    "    raw_data_path: str = os.path.join('artifacts', \"data.csv\")\n",
    "```\n",
    "The @dataclass decorator is used because it automatically generates several special methods like __init__ and __repr__, saving us from writing boilerplate code. This makes the configuration more maintainable and less prone to errors. We store paths in a configuration class because it centralizes all file paths in one place, making it easier to modify them if our directory structure changes in the future.\n",
    "\n",
    "**2. Why create a separate DataIngestion class?**\n",
    "```python\n",
    "class DataIngestion:\n",
    "    def __init__(self):\n",
    "        self.ingestion_config = DataIngestionConfig()\n",
    "```\n",
    "We create a separate class for data ingestion because it follows the Single Responsibility Principle - this class has one job: handling data ingestion. Having a dedicated class makes the code more organized and easier to maintain. It also makes it simpler to modify or extend data ingestion functionality without affecting other parts of the codebase.\n",
    "\n",
    "**3. Why implement logging throughout the process?**\n",
    "```python\n",
    "logging.info(\"Entered the data ingestion method or component\")\n",
    "logging.info('Read the dataset as dataframe')\n",
    "```\n",
    "Logging is implemented because it helps track the execution flow and debug issues in production. When something goes wrong, logs help us understand exactly where the problem occurred. This is especially important in data pipelines where operations can take a long time and multiple steps are involved.\n",
    "\n",
    "**4. Why create directories with exist_ok=True?**\n",
    "```python\n",
    "os.makedirs(os.path.dirname(self.ingestion_config.train_data_path), exist_ok=True)\n",
    "```\n",
    "We use exist_ok=True because we want our code to be idempotent - meaning it can be run multiple times without causing errors. If the directory already exists, we don't want the code to fail; we want it to continue executing. This makes the code more robust and reusable.\n",
    "\n",
    "**5. Why split the data into train and test sets?**\n",
    "```python\n",
    "train_set, test_set = train_test_split(df, test_size=0.2, random_state=42)\n",
    "```\n",
    "We split the data because we need separate datasets for training and testing our machine learning model. The training set (80% of data) is used to train the model, while the test set (20%) is kept separate to evaluate how well the model performs on unseen data. This helps us assess if our model generalizes well to new data.\n",
    "\n",
    "**6. Why save raw, train, and test data separately?**\n",
    "```python\n",
    "df.to_csv(self.ingestion_config.raw_data_path, index=False, header=True)\n",
    "train_set.to_csv(self.ingestion_config.train_data_path, index=False, header=True)\n",
    "test_set.to_csv(self.ingestion_config.test_data_path, index=False, header=True)\n",
    "```\n",
    "We save these separately because:\n",
    "- Raw data preservation allows us to rerun the pipeline with different parameters if needed\n",
    "- Separate train/test files make it easier to load the correct data for each phase\n",
    "- This structure supports reproducibility of our machine learning experiments\n",
    "\n",
    "**7. Why implement custom exception handling?**\n",
    "```python\n",
    "except Exception as e:\n",
    "    raise CustomException(e, sys)\n",
    "```\n",
    "Custom exception handling is implemented because it allows us to add context-specific error information and maintain consistent error handling throughout the application. This makes debugging easier and provides more meaningful error messages.\n",
    "\n",
    "**8. Why structure the main execution block this way?**\n",
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    obj = DataIngestion()\n",
    "    train_data, test_data = obj.initiate_data_ingestion()\n",
    "    data_transformation = DataTransformation()\n",
    "    train_arr, test_arr, _ = data_transformation.initiate_data_transformation(train_data, test_data)\n",
    "    modeltrainer = ModelTrainer()\n",
    "    print(modeltrainer.initiate_model_trainer(train_arr, test_arr))\n",
    "```\n",
    "This structure is chosen because it creates a clear pipeline where:\n",
    "1. First, we ingest the data\n",
    "2. Then we transform it into a suitable format\n",
    "3. Finally, we train our model\n",
    "\n",
    "This sequential organization makes the flow of data through the pipeline clear and maintainable. It also allows us to modify or debug each step independently.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LECTURE -5\n",
    "\n",
    "s1- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
